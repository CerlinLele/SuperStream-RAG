{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Schedule 2 Processor Example with PDFReader\n\nThis notebook demonstrates how to:\n1. Detect Schedule 2 PDFs using the router\n2. Process them with Schedule2Processor (using free PDFReader)\n3. Generate LlamaIndex documents for RAG\n4. Save extracted data for reference"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-06T04:13:12.289612Z",
     "start_time": "2026-01-06T04:13:04.010237Z"
    }
   },
   "source": "from pathlib import Path\nfrom ingest.processors.pdf.schedule2 import Schedule2Processor\nfrom ingest.processors.pdf import PDFRouter\nfrom ingest.indexer import IndexBuilder",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hy120\\Downloads\\AI project\\SuperStream-RAG\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Find Schedule 2 PDF\n",
    "\n",
    "Search for Schedule 2 PDF files in the data directory."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-06T04:14:53.785943Z",
     "start_time": "2026-01-06T04:14:53.775599Z"
    }
   },
   "source": "import os\n\n# Print current working directory for debugging\nprint(f\"Current working directory: {os.getcwd()}\")\n\n# Define the PDF directory\npdf_dir = Path(\n    \"data/raw/official-documents/3-ato-software-developers-portal/superstream-standard\"\n)\n\n# Check if directory exists\nif not pdf_dir.exists():\n    print(f\"Directory not found: {pdf_dir}\")\n    print(\"Checking parent directories...\")\n    \n    # Try to find the data directory by going up\n    for i in range(5):\n        test_path = Path(\"../\" * i) / pdf_dir\n        if test_path.exists():\n            pdf_dir = test_path\n            print(f\"Found at: {pdf_dir}\")\n            break\n\n# Find Schedule 2 files (recursive search)\nschedule2_files = list(pdf_dir.glob(\"**/*Schedule*2*Terms*.pdf\"))\n\nprint(f\"Found {len(schedule2_files)} Schedule 2 files\")\n\nif not schedule2_files:\n    print(\"No Schedule 2 files found\")\n    # List what's in the directory\n    if pdf_dir.exists():\n        print(f\"Contents of {pdf_dir}:\")\n        for item in pdf_dir.rglob(\"*.pdf\"):\n            print(f\"  - {item}\")\nelse:\n    pdf_path = schedule2_files[0]\n    print(f\"Found PDF: {pdf_path.name}\")\n    print(f\"Full path: {pdf_path.absolute()}\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: C:\\Users\\hy120\\Downloads\\AI project\\SuperStream-RAG\\ingest\\processors\\pdf\\schedule2\n",
      "Directory not found: data\\raw\\official-documents\\3-ato-software-developers-portal\\superstream-standard\n",
      "Checking parent directories...\n",
      "Found at: ..\\..\\..\\..\\data\\raw\\official-documents\\3-ato-software-developers-portal\\superstream-standard\n",
      "Found 1 Schedule 2 files\n",
      "Found PDF: Schedule_2_Terms_and_Definitions_v2.1.pdf\n",
      "Full path: C:\\Users\\hy120\\Downloads\\AI project\\SuperStream-RAG\\ingest\\processors\\pdf\\schedule2\\..\\..\\..\\..\\data\\raw\\official-documents\\3-ato-software-developers-portal\\superstream-standard\\schedules\\Schedule_2_Terms_and_Definitions_v2.1.pdf\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Route the PDF\n",
    "\n",
    "Use the PDFRouter to analyze and route the PDF to the appropriate processor."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-06T04:14:57.991029Z",
     "start_time": "2026-01-06T04:14:57.977512Z"
    }
   },
   "source": [
    "# Initialize router\n",
    "router = PDFRouter()\n",
    "plan = router.route(pdf_path)\n",
    "\n",
    "if plan:\n",
    "    print(\"Routing Result:\")\n",
    "    print(f\"  Schedule Type: {plan.schedule_type}\")\n",
    "    print(f\"  Processor Type: {plan.processor_type}\")\n",
    "    print(f\"  Extractors: {plan.extractors}\")\n",
    "    print(f\"  Description: {plan.description}\")\n",
    "else:\n",
    "    print(\"Document type not recognized!\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Routing Result:\n",
      "  Schedule Type: Schedule_2\n",
      "  Processor Type: table\n",
      "  Extractors: ['terminology']\n",
      "  Description: Terms and Definitions - Simple glossary table\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Step 3: Process Schedule 2 with PDFReader\n\nExtract terms and documents from the PDF using the free PDFReader."
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-06T04:15:07.772266Z",
     "start_time": "2026-01-06T04:15:07.011541Z"
    }
   },
   "source": [
    "# Initialize processor\n",
    "processor = Schedule2Processor()\n",
    "\n",
    "# Process the PDF\n",
    "print(\"Processing PDF with PDFReader...\")\n",
    "result = processor.process(pdf_path)\n",
    "\n",
    "# Access extracted data\n",
    "raw_content = result[\"raw_content\"]\n",
    "terms = result[\"terms\"]\n",
    "documents = result[\"documents\"]\n",
    "metadata = result[\"metadata\"]\n",
    "\n",
    "print(\"Processing completed!\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing PDF with PDFReader...\n",
      "Processing Schedule 2: Schedule_2_Terms_and_Definitions_v2.1.pdf\n",
      "  üîç Detecting version...\n",
      "\n",
      "  üìã Version Detection:\n",
      "     File: Schedule_2_Terms_and_Definitions_v2.1.pdf\n",
      "     Version: v2.1\n",
      "     Detected from: filename\n",
      "     Confidence: 95.0%\n",
      "     Processor: schedule2_v2\n",
      "  Parsing with PDFReader...\n",
      "  Successfully parsed 23 pages\n",
      "  Extracting terms from content...\n",
      "  Extracted 114 terms\n",
      "  Creating LlamaIndex documents...\n",
      "  Created 114 LlamaIndex documents\n",
      "Processing completed!\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: View Extraction Results\n",
    "\n",
    "Display the metadata and extracted terms."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"EXTRACTION RESULTS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nMetadata:\")\n",
    "for key, value in metadata.items():\n",
    "    print(f\"  {key}: {value}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: View Extracted Terms\n",
    "\n",
    "Display the first 10 extracted terms."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(f\"\\nExtracted Terms (first 10):\")\n",
    "for i, term in enumerate(terms[:10], 1):\n",
    "    print(f\"\\n{i}. {term.term}\")\n",
    "    print(f\"   Definition: {term.definition[:100]}...\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: View LlamaIndex Documents\n",
    "\n",
    "Display information about the generated documents for RAG."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(f\"LlamaIndex Documents:\")\n",
    "print(f\"  Total documents: {len(documents)}\")\n",
    "\n",
    "if documents:\n",
    "    print(f\"\\n  Sample document:\")\n",
    "    doc = documents[0]\n",
    "    print(f\"    ID: {doc.doc_id}\")\n",
    "    print(f\"    Text: {doc.text[:100]}...\")\n",
    "    print(f\"    Metadata: {doc.metadata}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Save Extracted Data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Save extracted data\n",
    "output_dir = Path(\"data/processed/terminology\")\n",
    "processor.save_extracted_data(result, output_dir)\n",
    "\n",
    "print(f\"Extracted data saved to {output_dir}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Build FAISS Index\n",
    "\n",
    "Create a FAISS index for RAG (Retrieval-Augmented Generation)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Build FAISS index\n",
    "print(\"Building FAISS Index...\")\n",
    "index_builder = IndexBuilder()\n",
    "index = index_builder.build_index(documents)\n",
    "\n",
    "print(f\"  Index built successfully!\")\n",
    "\n",
    "# Save index\n",
    "index_dir = Path(\"data/indices/schedule2_index\")\n",
    "index.storage_context.persist(str(index_dir))\n",
    "print(f\"  Index saved to {index_dir}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Summary\n\nThe notebook has successfully:\n- ‚úÖ Located the Schedule 2 PDF\n- ‚úÖ Routed the document to the appropriate processor\n- ‚úÖ Extracted terms and documents using PDFReader\n- ‚úÖ Saved extracted data\n- ‚úÖ Built and saved a FAISS index for RAG"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
