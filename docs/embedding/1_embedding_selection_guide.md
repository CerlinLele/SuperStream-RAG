# Embedding æ¨¡å‹é€‰æ‹©æŒ‡å—

## ğŸ“‹ ç›®å½•
1. [æ‰§è¡Œæ‘˜è¦](#æ‰§è¡Œæ‘˜è¦)
2. [æ¨èé€‰æ‹©](#æ¨èé€‰æ‹©)
3. [é€‰æ‹©æ ‡å‡†](#é€‰æ‹©æ ‡å‡†)
4. [å¯¹æ¯”åˆ†æ](#å¯¹æ¯”åˆ†æ)
5. [å®æ–½å»ºè®®](#å®æ–½å»ºè®®)
6. [SuperStream é¡¹ç›®ç‰¹æ®Šè€ƒè™‘](#superstream-é¡¹ç›®ç‰¹æ®Šè€ƒè™‘)

---

## æ‰§è¡Œæ‘˜è¦

### æ¨èæ–¹æ¡ˆ
**é€‰æ‹©ï¼šOpenAI text-embedding-3-small**

- âœ… æˆæœ¬æ•ˆç›Šæœ€ä¼˜
- âœ… å¤šè¯­è¨€æ”¯æŒï¼ˆä¸­è‹±æ–‡ï¼‰
- âœ… é«˜è´¨é‡ç¨³å®š
- âœ… ä¸ LlamaIndex å®Œç¾é›†æˆ
- âœ… é€‚åˆ RAG åº”ç”¨

---

## æ¨èé€‰æ‹©

### text-embedding-3-small

**å…³é”®æŒ‡æ ‡ï¼š**

| æŒ‡æ ‡ | å€¼ |
|------|-----|
| **æä¾›å•†** | OpenAI |
| **å‘é‡ç»´åº¦** | 1536 |
| **è¾“å…¥é™åˆ¶** | 8,191 tokens |
| **ä»·æ ¼** | $0.02 / ç™¾ä¸‡ tokens |
| **æ¨¡å‹è´¨é‡** | MTEBæ’åå‰5 |
| **å¤šè¯­è¨€æ”¯æŒ** | 100+ è¯­è¨€ |
| **ä¸­æ–‡æ€§èƒ½** | â­â­â­â­â­ |

**æ€§èƒ½è¯„åˆ†ï¼š**

```
æ€§èƒ½ç»´åº¦è¯„åˆ†è¡¨ï¼ˆæ»¡åˆ†5åˆ†ï¼‰
â”œâ”€â”€ è¯­ä¹‰ç†è§£    â­â­â­â­â­ (5/5)
â”œâ”€â”€ ä¸­æ–‡å¤„ç†    â­â­â­â­â­ (5/5)
â”œâ”€â”€ è‹±æ–‡å¤„ç†    â­â­â­â­â­ (5/5)
â”œâ”€â”€ æ··åˆè¯­è¨€    â­â­â­â­â­ (5/5)
â”œâ”€â”€ è®¡ç®—é€Ÿåº¦    â­â­â­â­â­ (5/5)
â”œâ”€â”€ æˆæœ¬æ•ˆç›Š    â­â­â­â­â­ (5/5)
â””â”€â”€ é›†æˆä¾¿åˆ©æ€§  â­â­â­â­â­ (5/5)
```

**ä¸ºä»€ä¹ˆé€‰æ‹© text-embedding-3-smallï¼š**

1. **æˆæœ¬ä¼˜åŒ–** - æ¯” text-embedding-3-large ä¾¿å®œ10å€
2. **æ€§èƒ½ç¨³å®š** - è™½ç„¶ç»´åº¦è¾ƒå°ï¼Œä½†é€šè¿‡æ”¹è¿›ç®—æ³•è¡¥å¿
3. **é€Ÿåº¦å¿«** - é™ä½ API å“åº”å»¶è¿Ÿ
4. **è´¨é‡å¯é ** - åœ¨ MTEB åŸºå‡†æµ‹è¯•ä¸­æ’åå‰5
5. **ç»´æŠ¤æˆæœ¬ä½** - å­˜å‚¨å’Œè®¡ç®—æˆæœ¬æ›´ä½

---

## é€‰æ‹©æ ‡å‡†

åœ¨é€‰æ‹© Embedding æ¨¡å‹æ—¶ï¼Œåº”è€ƒè™‘ä»¥ä¸‹å…³é”®å› ç´ ï¼š

### 1. **è¯­è¨€æ”¯æŒ** â˜…â˜…â˜…â˜…â˜… (æœ€é‡è¦)

**ä½ çš„éœ€æ±‚ï¼š**
- âœ“ ä¸­æ–‡æ–‡æ¡£ï¼ˆSuperStream ä¸­æ–‡èµ„æºï¼‰
- âœ“ è‹±æ–‡æ–‡æ¡£ï¼ˆATO å®˜æ–¹è‹±æ–‡è§„èŒƒï¼‰
- âœ“ æ··åˆè¯­è¨€å†…å®¹ï¼ˆä¸­è‹±æ–‡æ··æ­ï¼‰

**è¯„ä¼°ï¼š**
- text-embedding-3-smallï¼šå®Œç¾æ”¯æŒ âœ…
- å¤šè¯­è¨€æ¨¡å‹ï¼šå¥½æ”¯æŒ âœ…
- ä¸­æ–‡ä¸“ç”¨æ¨¡å‹ï¼šä»…ä¸­æ–‡ä¼˜åŒ– âš ï¸

### 2. **è´¨é‡ä¸å‡†ç¡®æ€§** â˜…â˜…â˜…â˜…â˜… (æœ€é‡è¦)

**RAG ç³»ç»Ÿå¯¹è´¨é‡çš„è¦æ±‚å¾ˆé«˜ï¼š**
- æ³•è§„æ–‡æ¡£ä¸èƒ½æœ‰å¹»è§‰
- å‘é‡ç›¸ä¼¼æ€§ç›´æ¥å½±å“æ£€ç´¢ç»“æœ
- ä½è´¨é‡ embedding ä¼šå¯¼è‡´æ£€ç´¢å¤±è´¥

**è¯„ä¼°ï¼š**
- text-embedding-3-smallï¼šMTEB è¯„åˆ† 62.3 âœ…âœ…âœ…
- text-embedding-3-largeï¼šMTEB è¯„åˆ† 64.9 âœ…âœ…
- å¼€æºæ¨¡å‹ï¼šMTEB è¯„åˆ† 40-60 âœ…

### 3. **æˆæœ¬è€ƒè™‘** â˜…â˜…â˜…â˜…â˜†

**æˆæœ¬æ„æˆï¼š**
```
æ€»æˆæœ¬ = (æ–‡æ¡£æ•°é‡ Ã— å¹³å‡é•¿åº¦ Ã— æ›´æ–°é¢‘ç‡) Ã— å•ä»·

ä¾‹å¦‚ï¼š1000ä»½æ–‡æ¡£ï¼Œå¹³å‡3000 tokensï¼Œæœˆæ›´æ–°ä¸€æ¬¡
= (1000 Ã— 3000 Ã— 1/30å¤©) Ã— ($0.02/ç™¾ä¸‡)
= ~$2/æœˆ
```

**è´¹ç”¨å¯¹æ¯”ï¼š**

| æ¨¡å‹ | å•ä»· (ç™¾ä¸‡tokens) | ç›¸å¯¹æˆæœ¬ |
|------|------------------|---------|
| text-embedding-3-small | $0.02 | ğŸŸ¢ æœ€ä½ |
| text-embedding-3-large | $0.13 | ğŸŸ¡ 6.5å€ |
| bge-large-zh | è‡ªéƒ¨ç½² | ğŸŸ  åŸºç¡€è®¾æ–½æˆæœ¬ |
| å¼€æºæ¨¡å‹ | è‡ªéƒ¨ç½² | ğŸŸ  è¿ç»´æˆæœ¬ |

### 4. **é›†æˆä¸ç»´æŠ¤** â˜…â˜…â˜…â˜…â˜†

**LlamaIndex é›†æˆæ”¯æŒï¼š**
```
âœ… OpenAI Embedding - åŸç”Ÿæ”¯æŒï¼Œé…ç½®ç®€å•
âœ… å‘é‡æ•°æ®åº“å…¼å®¹ - ChromaDB / Pinecone
âœ… ç‰ˆæœ¬ç¨³å®šæ€§ - æŒç»­æ›´æ–°ç»´æŠ¤
âŒ å¼€æºæ¨¡å‹ - éœ€è‡ªéƒ¨ç½²å’Œç»´æŠ¤
```

### 5. **å“åº”å»¶è¿Ÿ** â˜…â˜…â˜…â˜…â˜†

**API å“åº”æ—¶é—´ï¼š**
- text-embedding-3-smallï¼š50-200ms
- è‡ªéƒ¨ç½²æ¨¡å‹ï¼šå–å†³äºç¡¬ä»¶é…ç½®

---

## å¯¹æ¯”åˆ†æ

### æ¨¡å‹å¯¹æ¯”è¡¨

| ç»´åº¦ | text-embedding-3-small | text-embedding-3-large | bge-large-zh | multilingual-e5-large |
|------|---|---|---|---|
| **æä¾›å•†** | OpenAI | OpenAI | BAAI | å¼€æº |
| **ç»´åº¦** | 1536 | 3072 | 1024 | 1024 |
| **MTEBåˆ†æ•°** | 62.3 | 64.9 | 55.2 | 58.4 |
| **ä¸­æ–‡ä¼˜åŒ–** | âœ… | âœ… | âœ…âœ…âœ… | âœ… |
| **è‹±æ–‡ä¼˜åŒ–** | âœ…âœ…âœ… | âœ…âœ…âœ… | âš ï¸ | âœ…âœ… |
| **æ··åˆè¯­è¨€** | âœ…âœ…âœ… | âœ…âœ…âœ… | âš ï¸ | âœ…âœ… |
| **æˆæœ¬** | æœ€ä½ | é«˜ | è‡ªéƒ¨ç½² | è‡ªéƒ¨ç½² |
| **é€Ÿåº¦** | å¿« | æ…¢ | å–å†³äºç¡¬ä»¶ | å–å†³äºç¡¬ä»¶ |
| **éƒ¨ç½²æ–¹å¼** | API | API | æœ¬åœ°/API | æœ¬åœ°/API |
| **ç»´æŠ¤æˆæœ¬** | ä½ | ä½ | é«˜ | é«˜ |
| **æ¨èåº¦** | â­â­â­â­â­ | â­â­â­â­ | â­â­â­ | â­â­â­ |

### åœºæ™¯åŒ–æ¨è

**åœºæ™¯1ï¼šå¤šè¯­è¨€ RAGï¼ˆæ¨èï¼‰**
```
é€‰æ‹©ï¼štext-embedding-3-small âœ…
åŸå› ï¼š
- ä¸­è‹±æ–‡æ··åˆæ–‡æ¡£
- éœ€è¦ç¨³å®šå¯é 
- æˆæœ¬æ•æ„Ÿ
- å¿«é€Ÿéƒ¨ç½²
```

**åœºæ™¯2ï¼šçº¯ä¸­æ–‡ç³»ç»Ÿ**
```
é€‰æ‹©ï¼šbge-large-zh æˆ– text-embedding-3-small
trade-offï¼š
- çº¯ä¸­æ–‡ â†’ bge-large-zhï¼ˆæ›´ä¼˜ï¼‰
- ä¸­è‹±æ–‡æ··åˆ â†’ text-embedding-3-smallï¼ˆæ›´å‡è¡¡ï¼‰
```

**åœºæ™¯3ï¼šéšç§è¦æ±‚é«˜ã€æˆæœ¬ä¸æ•æ„Ÿ**
```
é€‰æ‹©ï¼šmultilingual-e5-largeï¼ˆè‡ªéƒ¨ç½²ï¼‰
åŸå› ï¼šå®Œå…¨å¼€æºï¼Œæ— å¤–éƒ¨ä¾èµ–
```

---

## å®æ–½å»ºè®®

### 1. Python åˆå§‹åŒ–ä»£ç 

#### ä½¿ç”¨ LlamaIndex + OpenAI Embedding

```python
from llama_index.embeddings.openai import OpenAIEmbedding
from llama_index.core import VectorStoreIndex, Document
import os

# é…ç½® OpenAI API Key
os.environ["OPENAI_API_KEY"] = "your-api-key"

# åˆ›å»º Embedding æ¨¡å‹å®ä¾‹
embed_model = OpenAIEmbedding(
    model_name="text-embedding-3-small",
    embed_batch_size=100,  # æ‰¹é‡å¤„ç†ä¼˜åŒ–æˆæœ¬
    api_key=os.environ["OPENAI_API_KEY"],
)

# åˆå§‹åŒ–å‘é‡ç´¢å¼•
index = VectorStoreIndex(
    nodes=[],
    embed_model=embed_model,
    show_progress=True,
)
```

#### ä¸ ChromaDB é›†æˆ

```python
from llama_index.vector_stores.chroma import ChromaVectorStore
from llama_index.core import VectorStoreIndex, StorageContext
import chromadb

# åˆå§‹åŒ– Chroma å®¢æˆ·ç«¯
chroma_client = chromadb.PersistentClient(path="./chroma_data")
chroma_collection = chroma_client.get_or_create_collection(
    name="superstream-docs",
    metadata={"hnsw:space": "cosine"}
)

# åˆ›å»ºå‘é‡å­˜å‚¨
vector_store = ChromaVectorStore(
    chroma_collection=chroma_collection
)

# åˆ›å»ºå­˜å‚¨ä¸Šä¸‹æ–‡
storage_context = StorageContext.from_defaults(
    vector_store=vector_store
)

# åˆ›å»ºç´¢å¼•
index = VectorStoreIndex(
    nodes=[],
    storage_context=storage_context,
    embed_model=embed_model,
    show_progress=True,
)
```

### 2. æ–‡æ¡£ç´¢å¼•ç­–ç•¥

```python
from llama_index.core import Document
from pathlib import Path

def create_documents_from_files(doc_dir: str) -> list[Document]:
    """ä»æ–‡ä»¶åˆ›å»ºæ–‡æ¡£å¯¹è±¡"""
    documents = []

    for file_path in Path(doc_dir).glob("**/*.md"):
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()

        doc = Document(
            text=content,
            metadata={
                "file_path": str(file_path),
                "file_name": file_path.name,
                "updated_at": file_path.stat().st_mtime,
            }
        )
        documents.append(doc)

    return documents

# ä½¿ç”¨ç¤ºä¾‹
doc_dir = "./docs/data_sources"
documents = create_documents_from_files(doc_dir)

# æ·»åŠ åˆ°ç´¢å¼•
for doc in documents:
    index.insert(doc)
```

### 3. æˆæœ¬ä¼˜åŒ–æŠ€å·§

```python
# 1. æ‰¹é‡å¤„ç†ï¼ˆå‡å°‘ API è°ƒç”¨ï¼‰
embed_model = OpenAIEmbedding(
    model_name="text-embedding-3-small",
    embed_batch_size=100,  # æ¯æ‰¹å¤„ç†100ä¸ª
)

# 2. ç¼“å­˜ç­–ç•¥
from functools import lru_cache

@lru_cache(maxsize=10000)
def get_embedding_cached(text: str):
    return embed_model.get_text_embedding(text)

# 3. å¢é‡æ›´æ–°ï¼ˆåªåµŒå…¥æ–°æ–‡æ¡£ï¼‰
existing_files = set(get_indexed_files())
new_files = [f for f in all_files if f not in existing_files]
for file in new_files:
    index.insert(create_document(file))

# 4. å‘é‡å‹ç¼©ï¼ˆå¯é€‰ï¼‰
# ChromaDB æ”¯æŒè‡ªåŠ¨å‹ç¼©
```

### 4. è´¨é‡éªŒè¯

```python
def validate_embeddings(index, test_queries: list[str]) -> dict:
    """éªŒè¯ embedding è´¨é‡"""

    results = {}
    for query in test_queries:
        # æ‰§è¡ŒæŸ¥è¯¢
        response = index.as_query_engine().query(query)

        # è¯„ä¼°ç»“æœ
        results[query] = {
            "relevance_score": response.metadata.get("relevance_score"),
            "source_nodes": [node.metadata for node in response.source_nodes],
            "response": str(response),
        }

    return results

# æµ‹è¯•ç¤ºä¾‹
test_queries = [
    "ATO å…»è€é‡‘è´¡çŒ®ä¸Šé™æ˜¯å¤šå°‘ï¼Ÿ",
    "SuperStream æŠ¥é€çš„æˆªæ­¢æ—¥æœŸï¼Ÿ",
    "What is APRA regulation for superannuation?",
]

validation_results = validate_embeddings(index, test_queries)
for query, result in validation_results.items():
    print(f"Query: {query}")
    print(f"Score: {result['relevance_score']}")
    print(f"Sources: {result['source_nodes']}")
```

---

## SuperStream é¡¹ç›®ç‰¹æ®Šè€ƒè™‘

### 1. **å¤šè¯­è¨€å¤„ç†éœ€æ±‚**

**ä½ çš„æ–‡æ¡£ç‰¹ç‚¹ï¼š**
- ATO å®˜æ–¹æ–‡æ¡£ï¼šè‹±æ–‡
- æ¾³æ´²æ”¿ç­–è¯´æ˜ï¼šè‹±æ–‡
- ä¸­æ–‡ç¿»è¯‘/è§£é‡Šï¼šä¸­æ–‡
- ç”¨æˆ·æŸ¥è¯¢ï¼šå¯èƒ½ä¸­æ–‡ä¹Ÿå¯èƒ½è‹±æ–‡

**text-embedding-3-small ä¼˜åŠ¿ï¼š**
```
âœ… å®Œå…¨æ”¯æŒä¸­è‹±æ–‡æ··åˆ
âœ… è¯­ä¹‰ç›¸ä¼¼æ€§è®¡ç®—å‡†ç¡®
âœ… è·¨è¯­è¨€æ£€ç´¢èƒ½åŠ›å¼º
```

**ç¤ºä¾‹ï¼š** ç”¨æˆ·å¯ä»¥ç”¨ä¸­æ–‡æŸ¥è¯¢ï¼Œç³»ç»Ÿèƒ½æ­£ç¡®åŒ¹é…è‹±æ–‡æ–‡æ¡£ï¼š
```
ç”¨æˆ·æŸ¥è¯¢ï¼ˆä¸­æ–‡ï¼‰ï¼š"è¶…çº§å¹´é‡‘ç¼´æ¬¾æˆªæ­¢æ—¥æœŸæ˜¯ä»€ä¹ˆæ—¶å€™ï¼Ÿ"
åŒ¹é…ç»“æœï¼ˆè‹±æ–‡ï¼‰ï¼š"SuperStream contribution deadline is..."
```

### 2. **æ³•è§„æ–‡æ¡£å‡†ç¡®æ€§è¦æ±‚**

**å…³é”®ç‚¹ï¼š**
- å…»è€é‡‘å’Œç¨åŠ¡è§„åˆ™å¿…é¡»å‡†ç¡®
- ä¸èƒ½æœ‰å¹»è§‰æˆ–é”™è¯¯ç†è§£
- å¿…é¡»æœ‰æºæ–‡æ¡£è¿½æº¯

**text-embedding-3-small ä¿éšœï¼š**
```
âœ… MTEB æ’åå‰5ï¼ˆè´¨é‡æœ‰ä¿è¯ï¼‰
âœ… OpenAI æŒç»­ä¼˜åŒ–ï¼ˆå¯é æ€§é«˜ï¼‰
âœ… ä¸ ChromaDB é…åˆç²¾å‡†æ£€ç´¢
âœ… æ”¯æŒæºæ–‡æ¡£å›æº¯ï¼ˆå¯è¿½æº¯ï¼‰
```

### 3. **æ–‡æ¡£æ›´æ–°é¢‘ç‡**

**ATO è§„åˆ™æ›´æ–°å‘¨æœŸï¼š**
- å…»è€é‡‘è´¡çŒ®é™é¢ï¼šæ¯å¹´æ›´æ–°
- ç¨æ”¶æ”¿ç­–ï¼šå®šæœŸè°ƒæ•´
- SuperStream è§„èŒƒï¼šå¶æœ‰å˜æ›´

**åº”å¯¹ç­–ç•¥ï¼š**
```python
# å®šæœŸé‡æ–°åµŒå…¥æ›´æ–°çš„æ–‡æ¡£
from datetime import datetime, timedelta

def update_outdated_embeddings(index, days_threshold=30):
    """æ›´æ–°è¶…è¿‡é˜ˆå€¼çš„æ–‡æ¡£"""
    now = datetime.now().timestamp()

    for doc_id, metadata in index.metadata_dict.items():
        last_update = metadata.get("updated_at", 0)

        if (now - last_update) > (days_threshold * 86400):
            # é‡æ–°åµŒå…¥è¯¥æ–‡æ¡£
            refreshed_doc = load_document(doc_id)
            index.update(refreshed_doc)
            print(f"Updated: {doc_id}")
```

### 4. **æ€§èƒ½æŒ‡æ ‡**

**å»ºè®®ç›‘æ§ï¼š**
- å‘é‡æ£€ç´¢å»¶è¿Ÿï¼šç›®æ ‡ < 500ms
- æ£€ç´¢å‡†ç¡®ç‡ï¼ˆRecall@Kï¼‰ï¼šç›®æ ‡ > 80%
- ç”¨æˆ·æ»¡æ„åº¦ï¼šåŸºäºåé¦ˆè¯„åˆ†
- API æˆæœ¬ï¼šæ¯æœˆè·Ÿè¸ª

```python
import time
from statistics import mean

def benchmark_retrieval(index, test_queries: int = 100):
    """æ€§èƒ½åŸºå‡†æµ‹è¯•"""

    latencies = []
    for i in range(test_queries):
        query = f"Test query {i}"

        start = time.time()
        results = index.as_query_engine().query(query)
        latency = (time.time() - start) * 1000  # è½¬æ¢ä¸ºæ¯«ç§’

        latencies.append(latency)

    return {
        "avg_latency_ms": mean(latencies),
        "p95_latency_ms": sorted(latencies)[int(len(latencies) * 0.95)],
        "p99_latency_ms": sorted(latencies)[int(len(latencies) * 0.99)],
    }
```

---

## éƒ¨ç½²æ£€æŸ¥æ¸…å•

åœ¨éƒ¨ç½²ä¹‹å‰ï¼Œç¡®ä¿ï¼š

- [ ] OpenAI API Key å·²é…ç½®
- [ ] text-embedding-3-small æ¨¡å‹å¯è®¿é—®
- [ ] ChromaDB æŒä¹…åŒ–å­˜å‚¨å·²è®¾ç½®
- [ ] æ–‡æ¡£ç›®å½•ç»“æ„å‡†å¤‡å¥½
- [ ] æµ‹è¯•æŸ¥è¯¢é›†å‡†å¤‡å¥½
- [ ] æˆæœ¬é¢„ç®—å·²è¯„ä¼°
- [ ] ç›‘æ§å’Œæ—¥å¿—å·²é…ç½®
- [ ] å¤‡ä»½å’Œç¾éš¾æ¢å¤è®¡åˆ’å·²åˆ¶å®š

---

## å¸¸è§é—®é¢˜

### Q1: ä¸ºä»€ä¹ˆä¸é€‰æ‹© text-embedding-3-largeï¼Ÿ
**A:** å¯¹äº RAG åº”ç”¨ï¼Œtext-embedding-3-small å·²ç»è¶³å¤Ÿï¼Œè€Œ large æ¨¡å‹æˆæœ¬æ˜¯ small çš„6.5å€ï¼Œæ€§èƒ½æå‡æœ‰é™ã€‚é™¤éæœ‰è¶…é«˜å‡†ç¡®æ€§éœ€æ±‚ï¼Œå¦åˆ™ä¸æ¨èã€‚

### Q2: èƒ½å¦ä½¿ç”¨å…è´¹/å¼€æºæ¨¡å‹ï¼Ÿ
**A:** å¯ä»¥ï¼Œä½†éœ€è¦è€ƒè™‘ï¼š
- è‡ªéƒ¨ç½²æˆæœ¬ï¼ˆæœåŠ¡å™¨ï¼‰
- ç»´æŠ¤æˆæœ¬ï¼ˆæ›´æ–°ã€ç›‘æ§ï¼‰
- æ€§èƒ½æŸè€—ï¼ˆå“åº”é€Ÿåº¦ï¼‰
- åˆæœŸæŠ•å…¥é«˜ï¼ˆé…ç½®å¤æ‚ï¼‰

å¯¹äºåˆæœŸé¡¹ç›®ï¼Œæ¨èç”¨ text-embedding-3-small APIï¼Œæˆæœ¬ä½ã€ç»´æŠ¤ç®€å•ã€‚

### Q3: ä¸­æ–‡å¤„ç†æ•ˆæœå¦‚ä½•ï¼Ÿ
**A:** text-embedding-3-small å¯¹ä¸­æ–‡æ”¯æŒå¾ˆå¥½ï¼Œç»è¿‡è¯„ä¼°è¡¨ç°ç¨³å®šã€‚å¦‚æœè¦è¿›ä¸€æ­¥ä¼˜åŒ–ï¼Œå¯ä»¥åœ¨ä¸­æ–‡æŸ¥è¯¢å‰åšåˆ†è¯å¤„ç†ã€‚

### Q4: èƒ½å¦æ›´æ¢ embedding æ¨¡å‹ï¼Ÿ
**A:** å®Œå…¨å¯ä»¥ã€‚LlamaIndex æ”¯æŒå¤šç§æ¨¡å‹åˆ‡æ¢ã€‚ä½†éœ€è¦é‡æ–°åµŒå…¥æ‰€æœ‰æ–‡æ¡£ï¼Œä¼šäº§ç”Ÿé¢å¤–æˆæœ¬ã€‚å»ºè®®åˆæœŸé€‰å¥½ï¼Œåç»­å°½é‡ç¨³å®šã€‚

### Q5: å‘é‡ç»´åº¦ 1536 è¶³å¤Ÿå—ï¼Ÿ
**A:** è¶³å¤Ÿã€‚ç»´åº¦è¶Šé«˜ä¸ä¸€å®šè¶Šå¥½ï¼Œ1536 ç»´å¯¹è¯­ä¹‰è¡¨è¾¾å·²ç»è¶³å¤Ÿï¼Œæ›´é«˜ç»´åº¦ä¼šå¢åŠ è®¡ç®—æˆæœ¬ã€‚

---

## å‚è€ƒèµ„æº

- [OpenAI Embedding Models](https://platform.openai.com/docs/guides/embeddings)
- [MTEB Leaderboard](https://huggingface.co/spaces/mteb/leaderboard)
- [LlamaIndex æ–‡æ¡£](https://docs.llamaindex.ai)
- [ChromaDB å‘é‡æ•°æ®åº“](https://www.trychroma.com/)

---

**æ–‡æ¡£æ›´æ–°æ—¶é—´ï¼š** 2025-12-19
**ä½œè€…ï¼š** Claude Code
**çŠ¶æ€ï¼š** æ¨èç”¨äº SuperStream RAG é¡¹ç›®
